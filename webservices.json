{"CRANTaskView": {"topic": {"#tail": "\n", "#text": "Web Technologies and Services"}, "name": {"#tail": "\n", "#text": "WebTechnologies"}, "info": {"ul": [{"li": [{"#tail": "\n", "code": [{"#tail": " after acquiring the csv file from the web via e.g., ", "#text": "read.csv()"}, {"#tail": " from RCurl. ", "#text": "getURL()"}, {"#tail": " works with http but not https, i.e.: ", "#text": "read.csv()"}, {"#tail": ", but not ", "#text": "read.csv(\"http://...\")"}, {"#tail": ".\n", "#text": "read.csv(\"https://...\")"}], "#text": "\ntxt, csv, etc.: you can use "}, {"#text": "\nThe ", "#tail": "\n", "pkg": {"#tail": " package contains a ", "#text": "repmis"}, "code": {"#tail": " command to load plain-text data from a URL (either http or https).\n", "#text": "source_data()"}}, {"#text": "\nThe package ", "#tail": "\n", "pkg": {"#tail": " contains functions for parsing XML and HTML, and supports xpath for searching XML (think regex for strings). A helpful function to read data from one or more HTML tables is ", "#text": "XML"}, "code": {"#tail": ".\n", "#text": "readHTMLTable()"}}, {"#tail": "\n", "a": {"#tail": ".\n", "@href": "https://github.com/cpsievert/XML2R", "#text": "here"}, "pkg": {"#tail": ": The XML2R package is a collection of convenient functions for coercing XML into data frames. The development version is on GitHub ", "#text": "XML2R"}, "#text": "\n"}, {"#tail": "\n", "a": [{"#tail": ", which parses CSS3 Selectors and translates them to XPath 1.0 expressions. ", "@href": "http://sjp.co.nz/projects/selectr/", "#text": "selectr"}, {"#tail": " translates CSS selectors to XPath, so can use the CSS selectors instead of XPath. The  ", "@href": "http://sjp.co.nz/projects/selectr/", "#text": "selectr"}, {"#tail": " can be used to identify page elements.\n", "@href": "http://selectorgadget.com/", "#text": "selectorgadget browser extension"}], "pkg": [{"#tail": " is ", "#text": "XML"}, {"#tail": " package is often used for parsing xml and html, but ", "#text": "XML"}], "#text": "\nAn alternative to "}, {"#tail": "\n", "pkg": {"#tail": " converts R object into Javascript object notation (JSON) objects and vice-versa.\n", "#text": "rjson"}, "#text": "\nThe "}, {"#tail": "\n", "pkg": [{"#tail": " is ", "#text": "rjson"}, {"#tail": " which also converts to and from data in JSON format (it is fast for parsing).\n", "#text": "RJSONIO"}], "#text": "\nAn alternative to the "}, {"#tail": "\n", "pkg": [{"#tail": " and ", "#text": "rjson"}, {"#tail": " is ", "#text": "RJSONIO"}, {"#tail": ", a fork of the ", "#text": "jsonlite"}, {"#tail": ". It includes the parser from RJSONIO, but implements a different mapping between R objects and JSON strings.\n", "#text": "RJSONIO"}], "#text": "\nAn alternative to "}, {"#tail": "\n", "pkg": [{"#tail": " and ", "#text": "XML"}, {"#tail": " or ", "#text": "rjson"}, {"#tail": ", respectively.\n", "#text": "RJSONIO"}], "#text": "\nCustom formats: Some web APIs provide custom data formats which are usually modified xml or json, and handled by "}, {"#tail": "\n", "a": {"#tail": " allows to read HTML documents and obtain a description of each of the forms it contains, along with the different elements and hidden fields\n", "@href": "http://www.omegahat.org/RHTMLForms/", "#text": "RHTMLForms"}, "#text": "\nThe "}, {"#tail": "\n", "pkg": {"#tail": " provides additional tools for scraping data from HTML and XML documents.\n", "#text": "scrapeR"}, "#text": "\n"}], "#tail": "\n\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "pkg": {"#tail": ": A low level curl wrapper that allows one to compose general HTTP requests and provides convenient functions to fetch URIs, get/post forms, etc. and process the results returned by the Web server. This provides a great deal of control over the HTTP/FTP connection and the form of the request while providing a higher-level interface than is available just using R socket connections. It also provide tools for Web authentication.\n", "#text": "RCurl"}, "#text": "\n"}, {"#text": "\n", "#tail": "\n", "pkg": [{"#tail": ": A light wrapper around ", "#text": "httr"}, {"#tail": " that makes many things easier, but still allows you to access the lower level functionality of ", "#text": "RCurl"}, {"#tail": ". It has convenient http verbs: ", "#text": "RCurl"}, {"#tail": ". The equivalent of httr's ", "#text": "RCurl"}, {"#tail": " is ", "#text": "RCurl"}, {"#tail": "'s ", "#text": "httr"}, {"#tail": " is ", "#text": "RCurl"}], "code": [{"#tail": ", ", "#text": "GET()"}, {"#tail": ", ", "#text": "POST()"}, {"#tail": ", ", "#text": "PUT()"}, {"#tail": ", ", "#text": "DELETE()"}, {"#tail": ", ", "#text": "PATCH()"}, {"#tail": ", ", "#text": "HEAD()"}, {"#tail": ". These wrap functions are more convenient to use, though less configurable than counterparts in ", "#text": "BROWSE()"}, {"#tail": " in ", "#text": "GET()"}, {"#tail": ". Likewise, the equivalent of ", "#text": "getForm()"}, {"#tail": " in ", "#text": "POST()"}, {"#tail": ". http status codes are helpful for debugging http calls. This package makes this easier using, for example, ", "#text": "postForm()"}, {"#tail": " gets the http status code from a response object, and stops the function if the call was not successful.  See also ", "#text": "stop_for_status()"}, {"#tail": ". Note that you can pass in additional Curl options to the ", "#text": "warn_for_status()"}, {"#tail": " parameter in http calls.\n", "#text": "config"}]}, {"#tail": "\n", "a": {"#tail": " package provides an implementation of XML-RPC, a relatively simple remote procedure call mechanism that uses HTTP and XML. This can be used for communicating between processes on a single machine or for accessing Web services from within R.\n", "@href": "http://www.omegahat.org/XMLRPC/", "#text": "XMLRPC"}, "#text": "\nThe "}, {"#tail": "\n", "a": {"#tail": " package provides facilities in R for reading XML schema documents and processing them to create definitions for R classes and functions for converting XML nodes to instances of those classes. It provides the framework for meta-computing with XML schema in R\n", "@href": "http://www.omegahat.org/XMLSchema/", "#text": "XMLSchema"}, "#text": "\nThe "}, {"#tail": "\n", "a": {"#tail": " interfaces to the libtidy library for correcting HTML documents that are not well-formed. This library corrects common errors in HTML documents.\n", "@href": "http://www.omegahat.org/RTidyHTML/", "#text": "RTidyHTML"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " provides a client-side SOAP (Simple Object Access Protocol) mechanism. It aims to provide a high-level interface to invoke SOAP methods provided by a SOAP server.\n", "@href": "http://www.omegahat.org/SSOAP/", "#text": "SSOAP"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": ": Interface to zlib and bzip2 libraries for performing in-memory compression and decompression in R. This is useful when receiving or sending contents to remote servers, e.g. Web services, HTTP requests via RCurl.\n", "@href": "http://www.omegahat.org/Rcompression/", "#text": "Rcompression"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " package allows one to use R scripts as CGI programs for generating dynamic Web content. HTML forms and other mechanisms to submit dynamic requests can be used to provide input to R scripts via the Web to create content that is determined within that R script.\n", "@href": "http://www.omegahat.org/CGIwithR/", "#text": "CGIwithR"}, "#text": "\nThe "}, {"#tail": "\n", "pkg": {"#tail": ": HTTP Request protocols. Implements the GET, POST and multipart POST request.\n", "#text": "httpRequest"}, "#text": "\n"}], "#tail": "\n\n", "#text": "\n"}, {"li": {"#tail": "\n", "pkg": [{"#tail": " or ", "#text": "RCurl"}, {"#tail": ". OAuth is the most complicated authentication process, and can be most easily done using ", "#text": "httr"}, {"#tail": ". See the 6 demos within ", "#text": "httr"}, {"#tail": ", three for OAuth 1.0 (linkedin, twitter, vimeo) and three for OAuth 2.0 (facebook, github, google). ", "#text": "httr"}, {"#tail": " is a package that provides a separate R interface to OAuth. OAuth is easier to to do in ", "#text": "ROAuth"}, {"#tail": ", so start there.\n", "#text": "httr"}], "#text": "\nUsing web resources can require authentication, either via API keys, OAuth, username:password combination, or via other means. Additionally, sometimes web resources that require authentication be in the header of an http call, which requires a little bit of extra work.  API keys and username:password combos can be combined within a url for a call to a web resource (api key: http://api.foo.org/?key=yourkey; user/pass: http://username:password@api.foo.org), or can be specified via commands in "}, "#tail": "\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "pkg": {"#tail": " package makes it easy to build interactive web applications with R.\n", "#text": "shiny"}, "#text": "\nThe "}, {"#tail": "\n", "pkg": {"#tail": " web server interface contains the specification and convenience software for building and running Rook applications.\n", "#text": "Rook"}, "#text": "\nThe "}, {"#tail": "\n", "pkg": {"#tail": " framework for embedded statistical computation and reproducible research exposes a web API interfacing R, LaTeX and Pandoc.\nThis API is used for example to integrate statistical functionality into systems, share and execute scripts or reports on centralized servers, and build R based apps.\n", "#text": "opencpu"}, "#text": "\nThe "}, {"#tail": "\n", "a": {"#tail": " called ", "@href": "http://yihui.name/", "#text": "Yihui Xie"}, "pkg": [{"#tail": " provides a simple HTTP server to serve files under a given directory based on the ", "#text": "servr"}, {"#tail": " package.\n", "#text": "httpuv"}], "#text": "\nA package by "}, {"#tail": "\n", "pkg": [{"#tail": " package, made by Joe Cheng at RStudio, provides low-level socket and protocol support for handling HTTP and WebSocket requests directly within R. Another related package, perhaps which ", "#text": "httpuv"}, {"#tail": " replaces, is websockets, also made by Joe Cheng.\n", "#text": "httpuv"}], "#text": "\nThe "}, {"#tail": "\n", "a": {"#tail": " A simple HTML5 websocket interface for R, by Joe Cheng. (not on CRAN)\n", "@href": "https://github.com/rstudio/R-Websockets", "#text": "websockets"}, "#text": "\n"}, {"#tail": "\n", "a": [{"#tail": ", as well as access to their services via an API ", "@href": "https://github.com/cparmer/Plotly/tree/master/API/packages/R", "#text": "here"}, {"#tail": ".\n", "@href": "https://plot.ly/API/", "#text": "here"}], "#text": "\nPlot.ly is a company that allows you to create visualizations in the web using R (and Python). They have an R package in development "}, {"#tail": "\n", "a": {"#tail": " package provides tools to process Web Application Description Language (WADL) documents and to programmatically generate R functions to interface to the REST methods described in those WADL documents.\n", "@href": "http://www.omegahat.org/WADL/", "#text": "WADL"}, "#text": "\nThe "}, {"#tail": "\n", "a": [{"#tail": " provides a mechanism to export R objects as (D)COM objects in Windows. It can be used along with the ", "@href": "http://www.omegahat.org/RDCOMServer/", "#text": "RDCOMServer"}, {"#tail": " package which provides user-level access from R to other COM servers.\n", "@href": "http://www.omegahat.org/RDCOMClient/", "#text": "RDCOMClient"}], "#text": "\nThe "}, {"#tail": "\n", "a": {"#tail": " package (not on CRAN) provides a set of R bindings for the Selenium 2.0 webdriver using the [JsonWireProtocol](http://code.google.com/p/selenium/wiki/JsonWireProtocol). Selenium automates browsers. Using RSelenium you can automate browsers locally or remotely. This can aid in automated application testing, load testing and web scraping. Examples are given interacting with popular projects such as [shiny](http://cran.r-project.org/web/packages/shiny/index.html) and [sauceLabs](http://saucelabs.com).", "@href": "https://github.com/johndharrison/RSelenium", "#text": "RSelenium"}, "#text": "The "}, {"#tail": "\n", "a": {"#tail": " provides an online environment (SaaS) to host and run ", "@href": "http://rapporter.net", "#text": "rapporter.net"}, "pkg": {"#tail": " statistical report templates in the cloud.\n", "#text": "rapport"}, "#text": "\n"}, {"#tail": "\n", "a": [{"#tail": " Wiki CMS/Groupware framework has an R plugin (", "@href": "http://info.tiki.org/tiki-index.php", "#text": "Tiki"}, {"#tail": ") to run R code from wiki pages, and use data from their own collected web databases (trackers). A demo: ", "@href": "https://doc.tiki.org/PluginR", "#text": "PluginR"}, {"#tail": ". More info in a ", "@href": "http://r.tiki.org/tiki-index.php", "#text": "http://r.tiki.org"}, {"#tail": ".\n", "@href": "http://ueb.vhir.org/2011+UseR", "#text": "useR!2013 presentation"}], "#text": "\nThe "}], "#tail": "\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "a": {"#tail": " (not on CRAN) makes it easy to describe interactive web graphics in R. It fuses the ideas of ggplot2 and ", "@href": "https://github.com/rstudio/ggvis", "#text": "ggvis"}, "pkg": {"#tail": ", rendering graphics on the web with Vega.\n", "#text": "shiny"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": "  (not on CRAN) allows for interactive javascript charts from R.\n", "@href": "https://github.com/ramnathv/rCharts", "#text": "rCharts"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " (not on CRAN) is an R wrapper for Vega.\n", "@href": "https://github.com/metagraf/rVega", "#text": "rVega"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " (not on CRAN) is an R package to create interactive plots.\n", "@href": "https://github.com/nachocab/clickme", "#text": "clickme"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " (not on CRAN) allows an interactive animation to be defined using a list of ggplots with clickSelects and showSelected aesthetics, then exported to CSV/JSON/D3/JavaScript for viewing in a web browser.\n", "@href": "https://github.com/tdhock/animint", "#text": "animint"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " package provides a means of evaluating JavaScript code, creating JavaScript objects and calling JavaScript functions and methods from within R. This can work by embedding the JavaScript engine within an R session or by embedding R in an browser such as Firefox and being able to call R from JavaScript and call back to JavaScript from R.\n", "@href": "http://www.omegahat.org/SpiderMonkey/", "#text": "SpiderMonkey"}, "#text": "\nThe "}], "#tail": "\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "pkg": {"#tail": ": A wrapper to the VertNet collections database API.\n", "#text": "rvertnet"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Interface to the Global Biodiversity Information Facility API methods.\n", "#text": "rgbif"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": A programmatic interface to fishbase.org.\n", "#text": "rfishbase"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": An R package for discovery, access and manipulation of online phylogenies.\n", "#text": "treebase"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Taxonomic information from around the web.\n", "#text": "taxize"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Species distribution modeling, with wrappers to some APIs.\n", "#text": "dismo"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " (not on CRAN): Access to the UK National Biodiversity Network data.\n", "@href": "https://github.com/JNCC-UK/rnbn", "#text": "rnbn"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " (not on CRAN): R interface for the World Bank climate data.\n", "@href": "https://github.com/ropensci/rWBclimate", "#text": "rWBclimate"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Wrapper to the USGS Bison API.\n", "#text": "rbison"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " (not on CRAN): Programmatic R interface to the Neotoma Paleoecological Database.\n", "@href": "https://github.com/ropensci/neotoma", "#text": "neotoma"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " (not on CRAN): Wrapper to the National Phenology Network database API.\n", "@href": "https://github.com/ropensci/rnpn", "#text": "rnpn"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Package for interacting with fisheries databases at openfisheries.org.\n", "#text": "rfisheries"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": A programmatic interface to the eBird database.\n", "#text": "rebird"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Retrieve taxonomical information of botanical names from the Flora do Brasil website.\n", "#text": "flora"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": This package provides programmatic access to Colombos, a web based interface for exploring and analyzing comprehensive organism-specific cross-platform expression compendia of bacterial organisms.\n", "#text": "Rcolombos"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": An R interface to the Encyclopedia of Life (EOL) API. Includes functions for downloading and extracting information off the EOL pages.\n", "#text": "Reol"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": "\n", "@href": "http://www.iplantcollaborative.org/discover/discovery-environment", "#text": "http://www.iplantcollaborative.org/discover/discovery-environment"}, "pkg": [{"#tail": ": An R interface to the the many computational resources iPlant offers through their RESTful application programming interface. Currently, ", "#text": "rPlant"}, {"#tail": " functions interact with the iPlant foundational API, the Taxonomic Name Resolution Service API, and the Phylotastic Taxosaurus API. Before using rPlant, users will have to register with the iPlant Collaborative. ", "#text": "rPlant"}], "#text": "\n"}, {"#tail": "\n", "a": [{"#tail": ") provides access to more than 2 million georeferenced specimen records from the Berkeley Natural History Museums. ", "@href": "http://ecoengine.berkeley.edu/", "#text": "http://ecoengine.berkeley.edu/"}, {"#tail": "\n", "@href": "http://bnhm.berkeley.edu/", "#text": "http://bnhm.berkeley.edu/"}], "pkg": {"#tail": ": The ecoengine (", "#text": "ecoengine"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": A programmatic interface to many species occurrence data sources, including GBIF, USGS's BISON, iNaturalist, Berkeley Ecoinformatics Engine eBird, AntWeb, and more as they sources become easily available.\n", "#text": "spocc"}, "#text": "\n"}], "#tail": "\n\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "pkg": {"#tail": ": R-Based API for accessing the MSKCC Cancer Genomics Data Server (CGDS).\n", "#text": "cgdsr"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": This package is a programmatic interface to various SNP datasets on the web: openSNP, NBCI's dbSNP database, and Broad Institute SNP Annotation and Proxy Search. This package started as a library to interact with openSNP alone, so most functions deal with openSNP.\n", "#text": "rsnps"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Talk with NCBI entrez using R.\n", "#text": "rentrez"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Exploratory data analysis and data visualization for biological sequence (DNA and protein) data.\n", "#text": "seqinr"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": ": Detect compositional changes in genomic sequences - with some interaction with GenBank. Archived on CRAN.\n", "@href": "http://cran.r-project.org/src/contrib/Archive/seq2R/", "#text": "seq2R"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Visually Assessing the Specificity and Informativeness of Primer Pairs.\n", "#text": "primerTree"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Information retrieval from NCBI databases, with main focus on Blast.\n", "#text": "hoardeR"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Download content from NCBI databases. Intended for analyses of NCBI database content, not reference management. See rpubmed for more literature oriented stuff from NCBI.\n", "#text": "RISmed"}, "#text": "\n"}], "#tail": "\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "pkg": {"#tail": ": Obtain, organize, and visualize NCEP weather data.\n", "#text": "RNCEP"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Provides the core functions required to download and format data from the Climate Reference Network. Both daily and hourly data are downloaded from the ftp, a consolidated file of all stations is created, station metadata is extracted. In addition functions for selecting individual variables and creating R friendly datasets for them is provided.\n", "#text": "crn"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": ": Data input for Berkeley Earth Surface Temperature. Archived on CRAN.\n", "@href": "http://cran.r-project.org/src/contrib/Archive/BerkeleyEarth/", "#text": "BerkeleyEarth"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": An R Package for retrieval, analysis, and anomaly calculation of daily hydrologic time series data.\n", "#text": "waterData"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": A compilation of historical through contemporary climate measurements scraped from the Environment Canada Website Including tools for scraping data, creating metadata and formating temperature files.\n", "#text": "CHCN"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Provides functions for retrieving energy statistics from the United Kingdom Department of Energy and Climate Change and related data sources. The current version focuses on total final energy consumption statistics at the local authority, MSOA, and LSOA geographies. Methods for calculating the generation mix of grid electricity and its associated carbon intensity are also provided.\n", "#text": "decctools"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": ": Collates metadata for climate surface stations. Archived on CRAN.\n", "@href": "http://cran.r-project.org/src/contrib/Archive/Metadata/", "#text": "Metadata"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": A client for Sensor Observation Services (SOS) as specified by the Open Geospatial Consortium (OGC). It allows users to retrieve metadata from SOS web services and to interactively create requests for near real-time observation data based on the available sensors, phenomena, observations etc. using thematic, temporal and spatial filtering.\n", "#text": "sos4R"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": ".\n", "@href": "https://github.com/RationShop/raincpc", "#text": "here"}, "pkg": {"#tail": ": The Climate Prediction Center's (CPC) daily rainfall data for the entire world, from 1979 to the present, at a resolution of 50 km (0.5 degrees lat-lon). This package provides functionality to download and process the raw data from CPC. Development version on GitHub ", "#text": "raincpc"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Functions that help in fetching weather data from websites. Given a location and a date range, these functions help fetch weather data (temperature, pressure etc.) for any weather related analysis.\n", "#text": "weatherData"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": A collection of functions for reading data from USDA-NCSS soil databases.\n", "#text": "soilDB"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": R interface to NOAA Climate data API.\n", "#text": "rnoaa"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": A package that downloads and processes Global Historical Climatology Network (GHCN) daily data from the National Climatic Data Center (NCDC).\n", "#text": "GhcnDaily"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Retrieves Oklahoma (USA) Mesonet climatological data provided by the Oklahoma Climatological Survey.\n", "#text": "okmesonet"}, "#text": "\n"}], "#tail": "\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "pkg": {"#tail": ": Search, extract and format data from the World Bank's World Development Indicators.\n", "#text": "WDI"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " package provides an R interface to the Zillow Web Service API. It allows one to get the Zillow estimate for the price of a particular property specified by street address and ZIP code (or city and state), to find information (e.g. size of property and lot, number of bedrooms and bathrooms, year built.) about a given property, and to get comparable properties.\n", "@href": "http://www.omegahat.org/Zillow/", "#text": "Zillow"}, "#text": "\nThe "}, {"#tail": "\n", "pkg": {"#tail": ": Interface for the REST API of Statistics Sweden. Fetch information on data hierarchy stored behind the API; extract metadata; fetch actual data; and clean up results.\n", "#text": "sweSCB"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": " Contains functions to download and format longitudinal datasets from the Panel Study of Income Dynamics (PSID).\n", "#text": "psidR"}, "#text": "\n"}], "#tail": "\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "a": [{"#tail": " (not on CRAN): An R interface to the ", "@href": "https://github.com/fcocquemas/rdatastream", "#text": "RDatastream"}, {"#tail": " (paid), with some convenience functions for retrieving Datastream data specifically.\n", "@href": "http://dataworks.thomson.com/Dataworks/Enterprise/1.0/", "#text": "Thomson Dataworks Enterprise SOAP API"}], "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " (not on CRAN): Another package for accessing the Datastream service. This package downloads data from the Thomson Reuters DataStream DWE server, which provides XML access to the Datstream database of economic and financial information.\n", "@href": "https://github.com/CharlesCara/Datastream2R", "#text": "Datastream2R"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Functions for financial quantitative modelling as well as data acqusition, plotting and other utilities.\n", "#text": "quantmod"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Connects to TrueFX(tm) for free streaming real-time and historical tick-by-tick market data for dealable interbank foreign exchange rates with millisecond detail.\n", "#text": "TFX"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Environment for teaching \"Financial Engineering and Computational Finance\"\n", "#text": "fImport"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Ineract with Bitcoin. Both public and private API calls. Support HTTP over SSL. Debug messages of Rbitcoin, debug messages of RCurl, error handling.\n", "#text": "Rbitcoin"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " API.\n", "@href": "http://www.thinknum.com/", "#text": "Thinknum"}, "pkg": {"#tail": ": Interacts with the ", "#text": "Thinknum"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": A package for downloading economic and financial time series from public sources.\n", "#text": "pdfetch"}, "#text": "\n"}, {"#text": "\n", "#tail": "\n", "pkg": {"#tail": ": Includes the ", "#text": "tseries"}, "code": {"#tail": " for historical financial data.\n", "#text": "get.hist.quote"}}], "#tail": "\n\n", "#text": "\n"}, {"li": {"#tail": "\n", "pkg": {"#tail": ": Interface to the PubChem Collection.\n", "#text": "rpubchem"}, "#text": "\n"}, "#tail": "\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "pkg": {"#tail": ": The package hosts a list of functions to download, manipulate, construct and aggregate agricultural statistics provided by the FAOSTAT (Food and Agricultural Organization of the United Nations) database.\n", "#text": "FAOSTAT"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": R package for retrieving data from CIMIS, the California Irrigation Management Information System.\n", "#text": "cimis"}, "#text": "\n"}], "#tail": "\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "pkg": {"#tail": ": A programmatic interface to the Web Service methods provided by the Public Library of Science journals for search.\n", "#text": "rplos"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": R interface to the Biodiversity Heritage Library (BHL) API.\n", "#text": "rbhl"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " (not on CRAN): Get scholarly metadata from around the web.\n", "@href": "https://github.com/ropensci/rmetadata", "#text": "rmetadata"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Implementation of the Mendeley API in R.\n", "#text": "RMendeley"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Talk with NCBI entrez using R.\n", "#text": "rentrez"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " (not on CRAN): A programmatic interface the Orcid.org API.\n", "@href": "https://github.com/ropensci/rorcid", "#text": "rorcid"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " (not on CRAN): Tools for extracting and processing Pubmed and Pubmed Central records.\n", "@href": "https://github.com/ropensci/rpubmed", "#text": "rpubmed"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Query and visualize metrics from Altmetric.com.", "#text": "rAltmetric"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": R wrapper to the almetrics API platform developed by PLoS.", "#text": "alm"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Retrieve and plot word frequencies through time from the Google Ngram Viewer.\n", "#text": "ngramr"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": " provides functions to extract citation data from Google Scholar. Convenience functions are also provided for comparing multiple scholars and predicting future h-index values.\n", "#text": "scholar"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " package is an R interface to Dan Veillard's libxslt translator. It allows R programmers to use XSLT directly from within R, and also allows XSL code to make use of R functions.\n", "@href": "http://www.omegahat.org/Sxslt/", "#text": "Sxslt"}, "#text": "\nThe "}, {"#tail": "\n", "a": {"#tail": " package provides an interface to the aspell library for checking the spelling of words and documents.\n", "@href": "http://www.omegahat.org/Aspell/", "#text": "Aspell"}, "#text": "\nThe "}, {"#tail": "\n", "pkg": {"#tail": ": Harvest metadata using the Open Archives Initiative Protocol for Metadata Harvesting (OAI-PMH).\n", "#text": "OAIHarvester"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Import and Manage BibTeX and BibLaTeX references with RefManager.\n", "#text": "RefManageR"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": ". Supports fetching text and XML from PubMed.\n", "@href": "http://www.ncbi.nlm.nih.gov/pubmed", "#text": "PubMed Abstracts"}, "pkg": {"#tail": ": An R package for text mining of ", "#text": "pubmed.mineR"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " for an intro.\n", "@href": "http://cran.r-project.org/web/packages/tm.plugin.webmining/vignettes/ShortIntro.pdf", "#text": "the vignette"}, "pkg": {"#tail": ": Retrieve structured text data from various web sources. Facilitates text retrieval from feed formats like XML (RSS, ATOM) and JSON. Also direct retrieval from HTML is supported. As most (news) feeds only incorporate small fractions of the original text tm.plugin.webmining even retrieves and extracts the text of the original text source. See ", "#text": "tm.plugin.webmining"}, "#text": "\n"}], "#tail": "\n\n", "#text": "\n"}, {"li": {"#tail": "\n", "pkg": {"#tail": ": Bidirectional connector to Anametrix API.\n", "#text": "anametrix"}, "#text": "\n"}, "#tail": "\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "pkg": {"#tail": ": Provides access to The Dataverse Network API.\n", "#text": "dvn"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Programmatic interface for Figshare.\n", "#text": "rfigshare"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Thin wrapper for the Factual.com server API.\n", "#text": "factualR"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": A package that provides read/write access to data and metadata from the DataONE network of Member Node data repositories.\n", "#text": "dataone"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Lets you deploy, maintain, and invoke models via the Yhat REST API.\n", "#text": "yhatr"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Provided with a Socrata dataset resource URL, or a Socrata SoDA web API query, returns an R data frame. Converts dates to POSIX format. Supports CSV and JSON. Manages throttling by Socrata.\n", "#text": "RSocrata"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " API to offer data in a number of formats usable in R, as well as the ability to upload and search.\n", "@href": "http://www.quandl.com/", "#text": "Quandl"}, "pkg": {"#tail": ": A package that interacts directly with the ", "#text": "Quandl"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Fetches data from DataMarket.com, either as timeseries in zoo form (dmseries) or as long-form data frames (dmlist).\n", "#text": "rdatamarket"}, "#text": "\n"}, {"#tail": "\n", "a": [{"#tail": ": An R wrapper for the infochimps.com API services, from ", "@href": "http://cran.r-project.org/src/contrib/Archive/infochimps/", "#text": "infochimps"}, {"#tail": ". The CRAN version is archived. Development ", "@href": "http://drewconway.com/", "#text": "Drew Conway"}, {"#tail": ".\n", "@href": "https://github.com/drewconway/infochimps", "#text": "on Github"}], "#text": "\n"}], "#tail": "\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "pkg": {"#tail": ": BigML, a machine learning web service.\n", "#text": "bigml"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Access to Amazon Mechanical Turk Requester API via R.\n", "#text": "MTurkR"}, "#text": "\n"}], "#tail": "\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "pkg": {"#tail": ": This package provides functions to interact with the Gaug.es API. Gaug.es is a web analytics service, like Google analytics. You have to have a Gaug.es account to use this package.\n", "#text": "rgauges"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Functions for accessing the Adobe Analytics (Omniture SiteCatalyst) Reporting API.\n", "#text": "RSiteCatalyst"}, "#text": "\n"}, {"gcode": {"#tail": " (not on CRAN): Provides access to Google Analytics.\n", "#text": "r-google-analytics"}, "#tail": "\n", "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " provides programmatic access to Google Trends data. This is information about the popularity of a particular query.\n", "@href": "http://www.omegahat.org/RGoogleTrends/", "#text": "RGoogleTrends"}, "#text": "\n"}], "#tail": "\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "pkg": {"#tail": ": Provides an interface to the Open Platform's Content API of the Guardian Media Group. It retrieves content from news outlets The Observer, The Guardian, and guardian.co.uk from 1999 to current day.\n", "#text": "GuardianR"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " provides interfaces to several of the New York Times Web services for searching articles, meta-data, user-generated content and best seller lists.\n", "@href": "http://www.omegahat.org/RNYTimes", "#text": "RNYTimes"}, "#text": "\n"}], "#tail": "\n\n\n", "#text": "\n"}, {"li": [{"#text": "\n", "#tail": "\n", "pkg": {"#tail": ": A package to share plots using the image hosting service imgur.com. (also see the function ", "#text": "imguR"}, "code": {"#tail": " in knitr, which uses the newer Imgur API version 3)\n", "#text": "imgur_upload()"}}, {"#tail": "\n", "a": {"#tail": ": A package to interface to the last.fm API. Archived on CRAN.\n", "@href": "http://cran.r-project.org/src/contrib/Archive/RLastFM/", "#text": "RLastFM"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " package provides an R interface to a Ubigraph server for drawing interactive, dynamic graphs.\nYou can add and remove vertices/nodes and edges in a graph and change their attributes/characteristics such as shape, color, size.\n", "@href": "http://www.omegahat.org/RUbigraph/", "#text": "RUbigraph"}, "#text": "\nThe "}], "#tail": "\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "pkg": {"#tail": ": Compiling the NHL Real Time Scoring System Database for easy use in R.\n", "#text": "nhlscrapr"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Tools for Collecting and Visualizing Major League Baseball PITCHfx Data\n", "#text": "pitchRx"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " (not on CRAN yet): Tools for Collecting Data from nba.com and wnba.com\n", "@href": "https://github.com/cpsievert/bbscrapeR", "#text": "bbscrapeR"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Association Football (Soccer) Ranking via Poisson Regression - uses time dependent Poisson regression and a record of goals scored in matches to rank teams via estimated attack and defense strengths.\n", "#text": "fbRanks"}, "#text": "\n"}], "#tail": "\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "pkg": {"#tail": ": This package serves two purposes: It provides a comfortable R interface to query the Google server for static maps, and use the map as a background image to overlay plots within R.\n", "#text": "RgoogleMaps"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " package - which is different from ", "@href": "http://www.omegahat.org/R2GoogleMaps/", "#text": "R2GoogleMaps"}, "pkg": {"#tail": " - provides a mechanism to generate JavaScript code from R that displays data using Google Maps.\n", "#text": "RgoogleMaps"}, "#text": "\nThe "}, {"#tail": "\n", "pkg": {"#tail": ": This package provides infrastructure to access OpenStreetMap data from different sources to work with the data in common R manner and to convert data into available infrastructure provided by existing R packages (e.g., into sp and igraph objects).\n", "#text": "osmar"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Allows for the easy visualization of spatial data and models on top of Google Maps, OpenStreetMaps, Stamen Maps, or CloudMade Maps using ggplot2.\n", "#text": "ggmap"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " package maps IP addresses and host names to geographic locations - latitude, longitude, region, city, zip code, etc.\n", "@href": "http://www.omegahat.org/GeoIP/", "#text": "GeoIP"}, "#text": "\nThe "}, {"#tail": "\n", "a": {"#tail": " is an implementation that provides users with high-level facilities to generate KML, the Keyhole Markup Language for display in, e.g., Google Earth.\n", "@href": "http://www.omegahat.org/RKML/", "#text": "RKML"}, "#text": "\nThe "}, {"#tail": "\n", "a": {"#tail": " allows to create R graphics in KML format in a manner that allows them to be displayed on Google Earth (or Google Maps).\n", "@href": "http://www.omegahat.org/RKMLDevice/", "#text": "RKMLDevice"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " allows you to display your spatial data on interactive web-maps using the open-source JavaScript library Leaflet.\n", "@href": "http://cran.r-project.org/web/packages/leafletR/index.html/", "#text": "LeafletR"}, "#text": "\n"}], "#tail": "\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "pkg": {"#tail": ": This package provides a series of functions that allow R users to access Twitter's filter, sample, and user streams, and to parse the output into data frames. OAuth authentication is supported.\n", "#text": "streamR"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Provides an interface to the Twitter web API.\n", "#text": "twitteR"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " package provides an R interface to the Flickr photo management and sharing application Web service.\n", "@href": "http://www.omegahat.org/Rflickr", "#text": "Rflickr"}, "#text": "\nThe "}, {"#tail": "\n", "pkg": {"#tail": ": Provides an interface to the Facebook API.\n", "#text": "Rfacebook"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": " has been designed to to facilitate the retrieval of Google+ profiles, pages and posts. It also provides search facilities. Currently a Google+ API key is required for accessing Google+ data.\n", "#text": "plusser"}, "#text": "\n"}], "#tail": "\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "pkg": {"#tail": ": Download, manipulate, and present data from the US Census American Community Survey.\n", "#text": "acs"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Client package for the U.S. Federal Register API.\n", "#text": "federalregister"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Functions to get public survey data in Japan.\n", "#text": "govStatJPN"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": An R client for the Huffpost Pollster API.\n", "#text": "pollstR"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Access U.S. Federal Government Recall Data.\n", "#text": "recalls"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": ProPublica API Client.\n", "#text": "RPublica"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": An R client for interacting with the White House's \"We The People\" petition API.\n", "#text": "wethepeople"}, "#text": "\n"}], "#tail": "\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "a": {"#tail": " provides programmatic access to the Google Storage API. This allows R users to access and store data on Google's storage. We can upload and download content, create, list and delete folders/buckets, and set access control permissions on objects and buckets.\n", "@href": "http://www.omegahat.org/RGoogleStorage/", "#text": "RGoogleStorage"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " package is an example of using the RCurl and XML packages to quickly develop an interface to the Google Documents API.\n", "@href": "http://www.omegahat.org/RGoogleDocs/", "#text": "RGoogleDocs"}, "#text": "\nThe "}, {"#tail": "\n", "pkg": {"#tail": ": Bindings for the Google Translate API v2\n", "#text": "translate"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": An R library to build Google's public data explorer DSPL metadata files.\n", "#text": "googlePublicData"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Interface between R and the Google chart tools.\n", "#text": "googleVis"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": A Google JSON data interpreter for R which contains a suite of helper functions for obtaining data from the Google Maps API JSON objects.\n", "#text": "gooJSON"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Plot SP or SPT(STDIF,STFDF) data as HTML map mashup over Google Maps.\n", "#text": "plotGoogleMaps"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Visualization of spatial and spatio-temporal objects in Google Earth.\n", "#text": "plotKML"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " (not on CRAN): An interface to Google's bigquery from R.\n", "@href": "https://github.com/hadley/bigrquery", "#text": "bigrquery"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " (not on CRAN): An R interface to Google Fusion Tables. Google Fusion Tables is a data mangement system in the cloud. This package provides R functions to browse Fusion Tables catalog, retrieve data from Gusion Tables dtd storage to R and to upload data from R to Fusion Tables\n", "@href": "http://gfusiontables.lopatenko.com/", "#text": "GFusionTables"}, "#text": "\n"}], "#tail": "\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "pkg": {"#tail": ": An R package to interact with Amazon Web Services (EC2/S3).\n", "#text": "AWS.tools"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " package provides the basic infrastructure within R for communicating with the S3 Amazon storage server.\nThis is a commercial server that allows one to store content and retrieve it from any machine connected to the Internet.\n", "@href": "http://www.omegahat.org/RAmazonS3", "#text": "RAmazonS3"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " provides an interface to Amazon's Simple DB API.\n", "@href": "http://www.omegahat.org/RAmazonDBREST", "#text": "RAmazonDBREST"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Access to Amazon Mechanical Turk Requester API via R.\n", "#text": "MTurkR"}, "#text": "\n"}], "#tail": "\n\n", "#text": "\n"}, {"li": [{"#tail": "\n", "pkg": {"#tail": ": R client for the OGC Sensor Observation Service.\n", "#text": "sos4R"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": Provides an S4 infrastructure for unified handling of internal datasets and web based data sources. Examples include dbpedia, eurostat and sourceforge.\n", "#text": "datamart"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " (not on CRAN): Dropbox interface.\n", "@href": "https://github.com/karthikram/rDrop", "#text": "rDrop"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": This package provides an R wrapper for the Zendesk API.\n", "#text": "zendeskR"}, "#text": "\n"}, {"#tail": "\n", "pkg": {"#tail": ": An R package to interact with Amazon Web Services (EC2/S3).\n", "#text": "AWS.tools"}, "#text": "\n"}, {"#tail": "\n", "a": {"#tail": " package provides functions to interact with the Qualtrics online survey tool.\n", "@href": "https://github.com/jbryer/qualtrics", "#text": "qualtrics"}, "#text": "\nThe "}, {"#tail": "\n", "pkg": {"#tail": ": RForcecom provides a connection to Force.com and Salesforce.com from R.\n", "#text": "RForcecom"}, "#text": "\n"}], "#tail": "\n\n", "#text": "\n"}], "#text": " This task view contains information about using R to obtain and parse data from the web. The base version of R does not ship with many tools for interacting with the web. Thankfully, there are an increasingly large number of tools for interacting with the web. A list of available packages and functions is presented below, grouped by the type of activity.\n\nIf you have any comments or suggestions for additions or improvements for this taskview, go to Github and ", "a": [{"#tail": ", or make some changes and ", "@href": "https://github.com/ropensci/webservices/issues", "#text": "submit an issue"}, {"#tail": ". If you can't contribute on Github, ", "@href": "https://github.com/ropensci/webservices/pulls", "#text": "submit a pull request"}, {"#tail": ". If you have an issue with one of the packages discussed below, please contact the maintainer of that package.\n\n", "@href": "mailto:scott@ropensci.org", "#text": "send Scott an email"}], "#tail": "\n\n", "p": [{"#tail": "\n", "strong": "Parsing Data from the Web"}, {"#tail": "\n", "strong": "Curl, HTTP, FTP, HTML, XML, SOAP"}, {"#tail": "\n", "strong": "Authentication"}, {"#tail": "\n\n", "strong": "Web Frameworks"}, {"#tail": "\n", "strong": "JavaScript"}, {"#tail": "\n\n", "strong": "Ecological and Evolutionary Biology"}, {"#tail": "\n\n", "strong": "Genes and Genomes"}, {"#tail": "\n\n", "strong": "Earth Science"}, {"#tail": "\n\n", "strong": "Economics and Business"}, {"#tail": "\n", "strong": "Finance"}, {"#tail": "\n", "strong": "Chemistry"}, {"#tail": "\n\n", "strong": "Agriculture"}, {"#tail": "\n\n", "strong": "Literature, Metadata, Text, and Altmetrics"}, {"#tail": "\n\n", "strong": "Marketing"}, {"#tail": "\n\n", "strong": "Data Depots"}, {"#tail": "\n\n", "strong": "Machine Learning as a Service"}, {"#tail": "\n\n", "strong": "Web Analytics"}, {"#tail": "\n\n", "strong": "News"}, {"#tail": "\n\n", "strong": "Images, Graphics, Videos, Music"}, {"#tail": "\n\n", "strong": "Sports"}, {"#tail": "\n\n", "strong": "Maps"}, {"#tail": "\n\n", "strong": "Social media"}, {"#tail": "\n\n", "strong": "Government"}, {"#tail": "\n", "strong": "Google Web Services"}, {"#tail": "\n", "strong": "Amazon Web Services"}, {"#tail": "\n\n", "strong": "Other"}], "h2": [{"#tail": "\n\n", "#text": "\nTools for Working with the Web from R\n"}, {"#tail": "\n\n", "#text": "\nData Sources on the Web Accessible via R\n"}]}, "version": {"#tail": "\n\n", "#text": "2014-04-30"}, "#text": "\n\n", "maintainer": {"@email": "scott@ropensci.org", "#tail": "\n", "#text": "Scott Chamberlain, Karthik Ram, Christopher Gandrud, Patrick Mair"}, "packagelist": {"#tail": "\n\n", "pkg": [{"#tail": "\n", "#text": "acs"}, {"#tail": "\n", "#text": "alm"}, {"#tail": "\n", "#text": "anametrix"}, {"#tail": "\n", "#text": "AWS.tools"}, {"#tail": "\n", "#text": "bigml"}, {"#tail": "\n", "#text": "cgdsr"}, {"#tail": "\n", "#text": "CHCN"}, {"#tail": "\n", "#text": "cimis"}, {"#tail": "\n", "#text": "crn"}, {"#tail": "\n", "#text": "datamart"}, {"#tail": "\n", "#text": "dataone"}, {"#tail": "\n", "#text": "decctools"}, {"#tail": "\n", "#text": "dismo"}, {"#tail": "\n", "#text": "dvn"}, {"#tail": "\n", "#text": "ecoengine"}, {"#tail": "\n", "#text": "factualR"}, {"#tail": "\n", "#text": "FAOSTAT"}, {"#tail": "\n", "#text": "fbRanks"}, {"#tail": "\n", "#text": "fImport"}, {"#tail": "\n", "#text": "flora"}, {"#tail": "\n", "#text": "ggmap"}, {"#tail": "\n", "#text": "GhcnDaily"}, {"#tail": "\n", "#text": "gooJSON"}, {"#tail": "\n", "#text": "googlePublicData"}, {"#tail": "\n", "#text": "googleVis"}, {"#tail": "\n", "#text": "govStatJPN"}, {"#tail": "\n", "#text": "GuardianR"}, {"#tail": "\n", "#text": "hoardeR"}, {"#tail": "\n", "#text": "httpuv"}, {"#tail": "\n", "#text": "httpRequest"}, {"@priority": "core", "#tail": "\n", "#text": "httr"}, {"#tail": "\n", "#text": "imguR"}, {"#tail": "\n", "#text": "MTurkR"}, {"#tail": "\n", "#text": "NCBI2R"}, {"#tail": "\n", "#text": "ngramr"}, {"#tail": "\n", "#text": "nhlscrapr"}, {"#tail": "\n", "#text": "OAIHarvester"}, {"#tail": "\n", "#text": "okmesonet"}, {"#tail": "\n", "#text": "opencpu"}, {"#tail": "\n", "#text": "osmar"}, {"#tail": "\n", "#text": "pdfetch"}, {"#tail": "\n", "#text": "pitchRx"}, {"#tail": "\n", "#text": "plotGoogleMaps"}, {"#tail": "\n", "#text": "plotKML"}, {"#tail": "\n", "#text": "plusser"}, {"#tail": "\n", "#text": "pollstR"}, {"#tail": "\n", "#text": "primerTree"}, {"#tail": "\n", "#text": "psidR"}, {"#tail": "\n", "#text": "pubmed.mineR"}, {"#tail": "\n", "#text": "Quandl"}, {"#tail": "\n", "#text": "quantmod"}, {"#tail": "\n", "#text": "rAltmetric"}, {"#tail": "\n", "#text": "raincpc"}, {"#tail": "\n", "#text": "rapport"}, {"#tail": "\n", "#text": "rbhl"}, {"#tail": "\n", "#text": "Rbitcoin"}, {"#tail": "\n", "#text": "Rcolombos"}, {"@priority": "core", "#tail": "\n", "#text": "RCurl"}, {"#tail": "\n", "#text": "rdatamarket"}, {"#tail": "\n", "#text": "rebird"}, {"#tail": "\n", "#text": "RefManageR"}, {"#tail": "\n", "#text": "Reol"}, {"#tail": "\n", "#text": "rentrez"}, {"#tail": "\n", "#text": "repmis"}, {"#tail": "\n", "#text": "Rfacebook"}, {"#tail": "\n", "#text": "rfigshare"}, {"#tail": "\n", "#text": "rfisheries"}, {"#tail": "\n", "#text": "rfishbase"}, {"#tail": "\n", "#text": "RForcecom"}, {"#tail": "\n", "#text": "rgauges"}, {"#tail": "\n", "#text": "rgbif"}, {"#tail": "\n", "#text": "rbison"}, {"#tail": "\n", "#text": "RISmed"}, {"#tail": "\n", "#text": "RgoogleMaps"}, {"@priority": "core", "#tail": "\n", "#text": "rjson"}, {"@priority": "core", "#tail": "\n", "#text": "RJSONIO"}, {"#tail": "\n", "#text": "rnoaa"}, {"#tail": "\n", "#text": "jsonlite"}, {"#tail": "\n", "#text": "RMendeley"}, {"#tail": "\n", "#text": "RNCBI"}, {"#tail": "\n", "#text": "RNCEP"}, {"#tail": "\n", "#text": "ROAuth"}, {"#tail": "\n", "#text": "Rook"}, {"#tail": "\n", "#text": "rPlant"}, {"#tail": "\n", "#text": "rplos"}, {"#tail": "\n", "#text": "rpubchem"}, {"#tail": "\n", "#text": "RSiteCatalyst"}, {"#tail": "\n", "#text": "rsnps"}, {"#tail": "\n", "#text": "RSocrata"}, {"#tail": "\n", "#text": "treebase"}, {"#tail": "\n", "#text": "rvertnet"}, {"#tail": "\n", "#text": "RWeather"}, {"#tail": "\n", "#text": "scholar"}, {"#tail": "\n", "#text": "scrapeR"}, {"#tail": "\n", "#text": "selectr"}, {"#tail": "\n", "#text": "seqinr"}, {"#tail": "\n", "#text": "servr"}, {"@priority": "core", "#tail": "\n", "#text": "shiny"}, {"#tail": "\n", "#text": "soilDB"}, {"#tail": "\n", "#text": "sos4R"}, {"#tail": "\n", "#text": "spocc"}, {"#tail": "\n", "#text": "streamR"}, {"#tail": "\n", "#text": "sweSCB"}, {"#tail": "\n", "#text": "SynergizeR"}, {"#tail": "\n", "#text": "taxize"}, {"#tail": "\n", "#text": "TFX"}, {"#tail": "\n", "#text": "Thinknum"}, {"#tail": "\n", "#text": "tm.plugin.webmining"}, {"#tail": "\n", "#text": "translate"}, {"#tail": "\n", "#text": "tseries"}, {"#tail": "\n", "#text": "twitteR"}, {"#tail": "\n", "#text": "waterData"}, {"#tail": "\n", "#text": "weatherData"}, {"#tail": "\n", "#text": "wethepeople"}, {"#tail": "\n", "#text": "WDI"}, {"@priority": "core", "#tail": "\n", "#text": "XML"}, {"#tail": "\n", "#text": "XML2R"}, {"#tail": "\n", "#text": "yhatr"}, {"#tail": "\n", "#text": "zendeskR"}], "#text": "\n"}, "links": {"#tail": "\n\n", "a": [{"#tail": "\n  ", "@href": "https://github.com/tdhock/animint", "#text": "GitHub package: animint"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/Aspell/", "#text": "Omegahat package: Aspell"}, {"#tail": "\n  ", "@href": "https://github.com/hadley/bigrquery", "#text": "GitHub package: bigrquery"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/CGIwithR/", "#text": "Omegahat package: CGIwithR"}, {"#tail": "\n  ", "@href": "https://github.com/nachocab/clickme", "#text": "GitHub package: clickme"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/GeoIP/", "#text": "Omegahat package: GeoIP"}, {"#tail": "\n  ", "@href": "https://github.com/rstudio/ggvis", "#text": "GitHub package: ggvis"}, {"#tail": "\n  ", "@href": "https://github.com/ropensci/neotoma", "#text": "GitHub package: neotoma"}, {"#tail": "\n  ", "@href": "https://github.com/jbryer/qualtrics", "#text": "GitHub package: qualtrics"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/R2GoogleMaps/", "#text": "Omegahat package: R2GoogleMaps"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/RAmazonDBREST", "#text": "Omegahat package: RAmazonDBREST"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/RAmazonS3", "#text": "Omegahat package: RAmazonS3"}, {"#tail": "\n  ", "@href": "https://github.com/ropensci/rbhl", "#text": "GitHub package: rbhl"}, {"#tail": "\n  ", "@href": "https://github.com/ropensci/rbison", "#text": "GitHub package: rbison"}, {"#tail": "\n  ", "@href": "https://github.com/ramnathv/rCharts", "#text": "GitHub package: rCharts"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/Rcompression/", "#text": "Omegahat package: Rcompression"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/RDCOMClient/", "#text": "Omegahat package: RDCOMClient"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/RDCOMServer/", "#text": "Omegahat package: RDCOMServer"}, {"#tail": "\n  ", "@href": "https://github.com/karthikram/rDrop", "#text": "GitHub package: rDrop"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/REuPathDB/", "#text": "Omegahat package: REuPathDB"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/Rflickr", "#text": "Omegahat package: Rflickr"}, {"#tail": "\n  ", "@href": "https://github.com/ropensci/rgauges", "#text": "GitHub package: rgauges"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/RGoogleDocs/", "#text": "Omegahat package: RGoogleDocs"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/RGoogleStorage/", "#text": "Omegahat package: RGoogleStorage"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/RGoogleTrends/", "#text": "Omegahat package: RGoogleTrends"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/RHTMLForms/", "#text": "Omegahat package: RHTMLForms"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/RKML/", "#text": "Omegahat package: RKML"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/RKMLDevice/", "#text": "Omegahat package: RKMLDevice"}, {"#tail": "\n  ", "@href": "https://github.com/ropensci/rmetadata", "#text": "GitHub package: rmetadata"}, {"#tail": "\n  ", "@href": "https://github.com/JNCC-UK/rnbn", "#text": "GitHub package: rnbn"}, {"#tail": "\n  ", "@href": "https://github.com/ropensci/rnpn", "#text": "GitHub package: rnpn"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/RNYTimes", "#text": "Omegahat package: RNYTimes"}, {"#tail": "\n  ", "@href": "https://github.com/ropensci/rorcid", "#text": "GitHub package: rorcid"}, {"#tail": "\n  ", "@href": "https://github.com/ropensci/rpubmed", "#text": "GitHub package: rpubmed"}, {"#tail": "\n  ", "@href": "https://github.com/ropensci/rsnps", "#text": "GitHub package: rsnps"}, {"#tail": "\n  ", "@href": "https://github.com/johndharrison/RSelenium", "#text": "GitHub package: RSelenium"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/RTidyHTML/", "#text": "Omegahat package: RTidyHTML"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/RUbigraph/", "#text": "Omegahat package: RUbigraph"}, {"#tail": "\n  ", "@href": "https://github.com/metagraf/rVega", "#text": "GitHub package: rVega"}, {"#tail": "\n  ", "@href": "https://github.com/ropensci/rWBclimate", "#text": "GitHub package: rWBclimate"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/SpiderMonkey/", "#text": "Omegahat package: SpiderMonkey"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/SSOAP/", "#text": "Omegahat package: SSOAP"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/Sxslt/", "#text": "Omegahat package: Sxslt"}, {"#tail": "\n  ", "@href": "https://github.com/cpsievert/XML2R", "#text": "GitHub package: XML2R"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/XMLRPC/", "#text": "Omegahat package: XMLRPC"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/XMLSchema/", "#text": "Omegahat package: XMLSchema"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/WADL/", "#text": "Omegahat package: WADL"}, {"#tail": "\n  ", "@href": "http://www.omegahat.org/Zillow/", "#text": "Omegahat package: Zillow"}, {"#tail": "\n  ", "@href": "https://github.com/fcocquemas/rdatastream", "#text": "GitHub package: RDatastream"}, {"#tail": "\n  ", "@href": "https://github.com/CharlesCara/Datastream2R", "#text": "GitHub package: Datastream2R"}, {"#tail": "\n  ", "@href": "http://cran.r-project.org/src/contrib/Archive/seq2R/", "#text": "CRAN archived package: seq2R"}, {"#tail": "\n  ", "@href": "http://cran.r-project.org/src/contrib/Archive/BerkeleyEarth/", "#text": "CRAN archived package: BerkeleyEarth"}, {"#tail": "\n  ", "@href": "http://cran.r-project.org/src/contrib/Archive/Metadata/", "#text": "CRAN archived package: Metadata"}, {"#tail": "\n  ", "@href": "http://cran.r-project.org/src/contrib/Archive/infochimps/", "#text": "CRAN archived package: infochimps"}, {"#tail": "\n  ", "@href": "http://cran.r-project.org/src/contrib/Archive/RLastFM/", "#text": "CRAN archived package: RLastFM"}, {"#tail": "\n  ", "@href": "http://gfusiontables.lopatenko.com/", "#text": "GFusionTables"}, {"#tail": "\n  ", "@href": "https://github.com/rstudio/R-Websockets", "#text": "GitHub package: websockets"}, {"#tail": "\n", "@href": "http://cran.r-project.org/src/contrib/Archive/websockets/", "#text": "CRAN archived package: websockets"}], "#text": "\n  "}}}
